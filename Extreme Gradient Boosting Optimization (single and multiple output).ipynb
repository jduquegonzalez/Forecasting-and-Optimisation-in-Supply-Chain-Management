{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccbd9480",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting\n",
    "(Comments and codes come from the Nicolas Vandepu's book \"Data Science for Supply Chain Forecasting\")\n",
    "\n",
    "Chen and Guestrin (from the University of Washington) proposed a new gradient boosting algorithm—called Extreme Gradient Boosting or XGBoost—and formalized it in 2016.2 The data science community has since widely used this implementation, with excellent results. This is simply one of the most powerful machine learning algorithms currently available.\n",
    "\n",
    "As users, XGBoost will bring us three improvements compared to AdaBoost and regular Gradient Boosting: \n",
    "                \n",
    "- XGBoost is faster. \n",
    "- XGBoost is (generally) better \n",
    "- XGBoost allows for more parameters to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a5e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Quantity                                                          \\\n",
      "Period        2007-01 2007-02 2007-03 2007-04 2007-05 2007-06 2007-07 2007-08   \n",
      "Make                                                                            \n",
      "Alfa Romeo         16       9      21      20      17      21      14      12   \n",
      "Aston Martin        0       0       1       0       4       3       3       0   \n",
      "Audi              599     498     682     556     630     498     562     590   \n",
      "BMW               352     335     365     360     431     477     403     348   \n",
      "Bentley             0       0       0       0       0       1       0       0   \n",
      "\n",
      "                              ...                                          \\\n",
      "Period       2007-09 2007-10  ... 2016-04 2016-05 2016-06 2016-07 2016-08   \n",
      "Make                          ...                                           \n",
      "Alfa Romeo        15      10  ...       3       1       2       1       6   \n",
      "Aston Martin       0       0  ...       0       0       1       0       0   \n",
      "Audi             393     554  ...     685     540     551     687     794   \n",
      "BMW              271     562  ...    1052     832     808     636    1031   \n",
      "Bentley            0       0  ...       0       0       1       1       1   \n",
      "\n",
      "                                                      \n",
      "Period       2016-09 2016-10 2016-11 2016-12 2017-01  \n",
      "Make                                                  \n",
      "Alfa Romeo        15       3       4       3       6  \n",
      "Aston Martin       0       0       0       0       0  \n",
      "Audi             688     603     645     827     565  \n",
      "BMW             1193    1096    1663     866    1540  \n",
      "Bentley            0       0       0       0       0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the import_data function\n",
    "def import_data():\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)\n",
    "    df = pd.pivot_table(data=data, values=['Quantity'], index='Make', columns='Period', aggfunc='sum', fill_value=0)\n",
    "    return df\n",
    "\n",
    "# URL of the CSV file\n",
    "file_path = \"https://supchains.com/wp-content/uploads/2021/07/norway_new_car_sales_by_make1.csv\"\n",
    "\n",
    "# Create the DataFrame using the import_data function\n",
    "df = import_data()\n",
    "\n",
    "# Now 'df' contains the data from the provided URL in the desired format.\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f4ac3",
   "metadata": {},
   "source": [
    "### Training and Test Sets Creation\n",
    "Now that we have our dataset with the proper formatting, we can create a function datasets() to populate a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7d785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the datasets function with x_len as an argument\n",
    "def datasets(df, x_len=12, y_len=1, test_loops=12):\n",
    "    D = df.values\n",
    "    rows, periods = D.shape\n",
    "    \n",
    "    # Training set creation\n",
    "    loops = periods + 1 - x_len - y_len\n",
    "    train = []\n",
    "    for col in range(loops):\n",
    "        train.append(D[:, col:col + x_len + y_len])\n",
    "    train = np.vstack(train)\n",
    "    X_train, Y_train = np.split(train, [-y_len], axis=1)\n",
    "    \n",
    "    # Test set creation\n",
    "    if test_loops > 0:\n",
    "        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)\n",
    "        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)\n",
    "    else:\n",
    "        X_test = D[:, -x_len:]\n",
    "        Y_test = np.full((X_test.shape[0], y_len), np.nan)\n",
    "    \n",
    "    # Formatting required for scikit-learn\n",
    "    if y_len == 1:\n",
    "        Y_train = Y_train.ravel()\n",
    "        Y_test = Y_test.ravel()\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fafc95",
   "metadata": {},
   "source": [
    "### Call our new function datasets(df) as well as import_data()\n",
    "We can now easily call our new function datasets(df) as well as import_data(). We obtain the datasets we need to feed our machine learning algorithm (X_train and Y_train) and the datasets we need to test it (X_test and Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2239cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = import_data()\n",
    "\n",
    "# Create training and test sets using the datasets function\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=1, test_loops=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1e1c1",
   "metadata": {},
   "source": [
    "### Analyzing Feature Importance with XGBoost in Machine Learning\n",
    "Machine learning algorithms often operate on large datasets with numerous features, making it essential to understand the importance of each feature in the model's predictions. XGBoost, an efficient and scalable machine learning algorithm, provides a built-in method to assess feature importance. In this code snippet, we utilize XGBoost to create a regression model and analyze the importance of features using its plotting capabilities. Let's delve into the organized version of the code to gain insights into how feature importance is visualized and interpreted in the context of machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ad9071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAHHCAYAAAC1G/yyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABLmUlEQVR4nO3dfVxUdf7//+dhxFEIvECMoEHxKrNS0ZIsySwVWjbXatc1zRzJkg1yy3I3akuozLIL22+xullCfVakrSXWSiwy2dqu9lPpbhdGeYFaZq2VoiIwyvn94Y/5nIkLmZGrYR73243bct7nvM95vYaRnnsuBsM0TVMAAACQJAW1dwEAAAAdCeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QhAp5KXlyfDMFReXt7epQDwU4QjwM/VhYGGvm6//fZWOeY777yjrKws7d+/v1X2H8gqKyuVlZWl0tLS9i4FCFhd2rsAAC3jnnvuUVxcnMfY2Wef3SrHeuedd5SdnS2n06mePXu2yjF8NWvWLE2fPl12u729S/FJZWWlsrOzJUkXX3xx+xYDBCjCEdBJXHbZZTr33HPbu4yTcvjwYYWGhp7UPmw2m2w2WwtV1HZqa2tVU1PT3mUAEJfVgIBRXFysxMREhYaGKiwsTCkpKfr00089tvnPf/4jp9OpAQMGqFu3boqKilJqaqq+//579zZZWVlauHChJCkuLs59Ca+8vFzl5eUyDEN5eXn1jm8YhrKysjz2YxiGPvvsM82YMUO9evXSuHHj3Ov/8pe/aPTo0erevbt69+6t6dOna/fu3Sfss6F7jvr376+f//znKi0t1bnnnqvu3bvrnHPOcV+6Kiws1DnnnKNu3bpp9OjR2rRpk8c+nU6nTjnlFG3fvl1JSUkKDQ1VdHS07rnnHpmm6bHt4cOHdeutt8rhcMhut+uMM87Qww8/XG87wzCUkZGh1atX66yzzpLdbteKFSsUGRkpScrOzna/tnWvW3N+PtbXduvWre6zez169NCcOXNUWVlZ7zX7y1/+ojFjxigkJES9evXSRRddpNdee81jm+a8f4DOgjNHQCdx4MAB7du3z2OsT58+kqT/+Z//0ezZs5WUlKQHH3xQlZWVWr58ucaNG6dNmzapf//+kqSSkhJt375dc+bMUVRUlD799FM9+eST+vTTT/Xee+/JMAxdeeWV+uKLL7RmzRotW7bMfYzIyEj997//9bruX/3qVxo8eLDuv/9+d4BYvHix7rrrLk2bNk1z587Vf//7Xz3++OO66KKLtGnTJp8u5W3dulUzZszQvHnzdM011+jhhx/W5ZdfrhUrVuiOO+7QjTfeKElasmSJpk2bprKyMgUF/d//fzx27JiSk5N1/vnna+nSpVq/fr0WLVqko0eP6p577pEkmaapKVOmaOPGjbruuus0cuRIvfrqq1q4cKG+/vprLVu2zKOmN954Q3/961+VkZGhPn36aMSIEVq+fLl+85vf6IorrtCVV14pSRo+fLik5v18rKZNm6a4uDgtWbJEH330kZ566in17dtXDz74oHub7OxsZWVl6YILLtA999yjrl276v3339cbb7yhyZMnS2r++wfoNEwAfi03N9eU1OCXaZrmwYMHzZ49e5rXX3+9x7y9e/eaPXr08BivrKyst/81a9aYksw333zTPfbQQw+ZkswdO3Z4bLtjxw5Tkpmbm1tvP5LMRYsWuZcXLVpkSjKvvvpqj+3Ky8tNm81mLl682GP8448/Nrt06VJvvLHXw1pbv379TEnmO++84x579dVXTUlm9+7dzZ07d7rH//znP5uSzI0bN7rHZs+ebUoyb7rpJvdYbW2tmZKSYnbt2tX873//a5qmaRYVFZmSzPvuu8+jpl/+8pemYRjm1q1bPV6PoKAg89NPP/XY9r///W+916pOc38+da9tamqqx7ZXXHGFGRER4V7+8ssvzaCgIPOKK64wjx075rFtbW2taZrevX+AzoLLakAnkZOTo5KSEo8v6fjZhv379+vqq6/Wvn373F82m00JCQnauHGjex/du3d3f19VVaV9+/bp/PPPlyR99NFHrVJ3Wlqax3JhYaFqa2s1bdo0j3qjoqI0ePBgj3q9MWzYMI0dO9a9nJCQIEm65JJLFBsbW298+/bt9faRkZHh/r7uslhNTY1ef/11SdK6detks9k0f/58j3m33nqrTNNUcXGxx/j48eM1bNiwZvfg7c/np69tYmKivv/+e1VUVEiSioqKVFtbq7vvvtvjLFldf5J37x+gs+CyGtBJjBkzpsEbsr/88ktJx0NAQ8LDw93f//DDD8rOzlZBQYG+++47j+0OHDjQgtX+n58+Yffll1/KNE0NHjy4we2Dg4N9Oo41AElSjx49JEkOh6PB8R9//NFjPCgoSAMGDPAYGzJkiCS572/auXOnoqOjFRYW5rHdmWee6V5v9dPeT8Tbn89Pe+7Vq5ek472Fh4dr27ZtCgoKajKgefP+AToLwhHQydXW1ko6ft9IVFRUvfVduvzfr4Fp06bpnXfe0cKFCzVy5Eidcsopqq2tVXJysns/TfnpPS91jh071ugc69mQunoNw1BxcXGDT52dcsopJ6yjIY09wdbYuPmTG6hbw097PxFvfz4t0Zs37x+gs+BdDXRyAwcOlCT17dtXEydObHS7H3/8URs2bFB2drbuvvtu93jdmQOrxkJQ3ZmJn3445E/PmJyoXtM0FRcX5z4z0xHU1tZq+/btHjV98cUXkuS+Iblfv356/fXXdfDgQY+zR59//rl7/Yk09tp68/NproEDB6q2tlafffaZRo4c2eg20onfP0Bnwj1HQCeXlJSk8PBw3X///XK5XPXW1z1hVneW4adnFR577LF6c+o+i+inISg8PFx9+vTRm2++6TH+pz/9qdn1XnnllbLZbMrOzq5Xi2ma9R5bb0tPPPGERy1PPPGEgoODdemll0qSfvazn+nYsWMe20nSsmXLZBiGLrvsshMeIyQkRFL919abn09zTZ06VUFBQbrnnnvqnXmqO05z3z9AZ8KZI6CTCw8P1/LlyzVr1iyNGjVK06dPV2RkpHbt2qVXXnlFF154oZ544gmFh4froosu0tKlS+VyuRQTE6PXXntNO3bsqLfP0aNHS5LuvPNOTZ8+XcHBwbr88ssVGhqquXPn6oEHHtDcuXN17rnn6s0333SfYWmOgQMH6r777lNmZqbKy8s1depUhYWFaceOHXrxxRd1ww036Lbbbmux16e5unXrpvXr12v27NlKSEhQcXGxXnnlFd1xxx3uzya6/PLLNWHCBN15550qLy/XiBEj9Nprr+nvf/+7br75ZvdZmKZ0795dw4YN03PPPachQ4aod+/eOvvss3X22Wc3++fTXIMGDdKdd96pe++9V4mJibryyitlt9v1v//7v4qOjtaSJUua/f4BOpV2ekoOQAupe3T9f//3f5vcbuPGjWZSUpLZo0cPs1u3bubAgQNNp9NpfvDBB+5tvvrqK/OKK64we/bsafbo0cP81a9+Ze7Zs6fBR8vvvfdeMyYmxgwKCvJ4dL6ystK87rrrzB49ephhYWHmtGnTzO+++67RR/nrHoP/qb/97W/muHHjzNDQUDM0NNQcOnSomZ6ebpaVlTXr9fjpo/wpKSn1tpVkpqene4zVfRzBQw895B6bPXu2GRoaam7bts2cPHmyGRISYp566qnmokWL6j0Cf/DgQfOWW24xo6OjzeDgYHPw4MHmQw895H40vqlj13nnnXfM0aNHm127dvV43Zr782nstW3otTFN01y1apUZHx9v2u12s1evXub48ePNkpISj22a8/4BOgvDNNvgrkMA8GNOp1MvvPCCDh061N6lAGgD3HMEAABgQTgCAACwIBwBAABYcM8RAACABWeOAAAALAhHAAAAFnwIZDPU1tZqz549CgsLa/Sj/QEAQMdimqYOHjyo6OhoBQU1/3wQ4agZ9uzZU+8vdwMAAP+we/dunX766c3ennDUDHV/QHLHjh3q3bt3O1fTNlwul1577TVNnjxZwcHB7V1Om6Bneu6s6JmeO6sT9VxRUSGHw+Hxh6Cbg3DUDHWX0sLCwhQeHt7O1bQNl8ulkJAQhYeHB9Q/Mnru/OiZnjsrem68Z29vieGGbAAAAAvCEQAAgAXhCAAAwIJwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QgAAMCCcAQAAGBBOAIAALDo8OHI6XTKMAylpaXVW5eeni7DMOR0OhudX1hYqMmTJysiIkKGYWjz5s2tVywAAPB7HT4cSZLD4VBBQYGOHDniHquqqlJ+fr5iY2ObnHv48GGNGzdODz74YGuXCQAAOoEu7V1Ac4waNUrbtm1TYWGhZs6cKen4GaHY2FjFxcU1OXfWrFmSpPLy8pOuI2HJBh3tEnrS+/EHdpuppWOks7NeVfUxo73LaRP0TM+dFT3Tc0spfyClVfbb0fjFmSNJSk1NVW5urnt51apVmjNnTjtWBAAAOiO/OHMkSddcc40yMzO1c+dOSdLbb7+tgoIClZaWtvixqqurVV1d7V6uqKiQJNmDTNlsZosfryOyB5ke/xsI6Dkw0HNgoOfW4XK5Wm3fvqirp7G6fK3XME2zQ79znE6n9u/fr6KiIl111VUaPny4TNPUJ598ohdeeEFTp05Vz549NWnSJM2bN889r7i4WImJie7l8vJyxcXFadOmTRo5cmSTx8zKylJ2dna98fz8fIWEhLRYbwAAoPVUVlZqxowZOnDggMLDw5s9z2/OHEnHL61lZGRIknJycjzWTZkyRQkJCe7lmJgYn4+TmZmpBQsWuJcrKirkcDh036YgHQ22+bxff2IPMnXvubW664MgVdcGyPV6em7vctoEPdNzZ9UWPX+SldQq+/WVy+VSSUmJJk2apODg4Hrr6678eMuvwlFycrJqampkGIaSkjx/QGFhYQoLC2uR49jtdtnt9nrjb/5+oiIiIlrkGB2dy+XSunXr9OHdyQ2+4Tojeqbnzoqe6bmzCw4ObrBnX18HvwpHNptNW7ZscX/fHD/88IN27dqlPXv2SJLKysokSVFRUYqKimqdQgEAgN/ym6fV6oSHh3t13XDt2rWKj49XSsrxxw+nT5+u+Ph4rVixorVKBAAAfqzDnznKy8trcn1RUVGT651OZ5OfoA0AAGDld2eOAAAAWhPhCAAAwIJwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QgAAMCiXcOR0+mUYRhKS0urty49PV2GYcjpdDY6v7CwUJMnT1ZERIQMw9DmzZs91v/www+66aabdMYZZ6h79+6KjY3V/PnzdeDAgRbuBAAAdBZd2rsAh8OhgoICLVu2TN27d5ckVVVVKT8/X7GxsU3OPXz4sMaNG6dp06bp+uuvr7d+z5492rNnjx5++GENGzZMO3fuVFpamvbs2aMXXnjB61oTlmzQ0S6hXs/zR3abqaVjpLOzXlX1MeOk91f+QEoLVAUAQOtr93A0atQobdu2TYWFhZo5c6ak42eEYmNjFRcX1+TcWbNmSZLKy8sbXH/22Wfrb3/7m3t54MCBWrx4sa655hodPXpUXbq0e/sAAKCD6RDpIDU1Vbm5ue5wtGrVKs2ZM0elpaUtfqwDBw4oPDy8yWBUXV2t6upq93JFRYUkyR5kymYzW7ymjsgeZHr878lyuVwtsp/WVFejP9TaUug5MNBzYKDnxtd7yzBNs93+a+90OrV//36tXLlSDodDZWVlkqShQ4dq9+7dmjt3rnr27Km8vLwm91NeXq64uDht2rRJI0eObHS7ffv2afTo0brmmmu0ePHiRrfLyspSdnZ2vfH8/HyFhIQ0qzcAANC+KisrNWPGDPeJkebqEGeOIiMjlZKSory8PJmmqZSUFPXp08e9fvXq1Zo3b557ubi4WImJiV4do6KiQikpKRo2bJiysrKa3DYzM1MLFizwmOtwOHTfpiAdDbZ5dVx/ZQ8yde+5tbrrgyBV1578PUefZCW1QFWty+VyqaSkRJMmTVJwcHB7l9Mm6JmeOyt6pmfp/678eKtDhCPp+KW1jIwMSVJOTo7HuilTpighIcG9HBMT49W+Dx48qOTkZIWFhenFF1884ZvGbrfLbrfXG6+uNXS0BW5O9ifVtUaL3JDtT/9Qg4OD/arelkDPgYGeAwM9e477osOEo+TkZNXU1MgwDCUleZ5lCAsLU1hYmE/7raioUFJSkux2u9auXatu3br5XOP7mZcqIiLC5/n+xOVyad26dfokKyng/pEBAAJbhwlHNptNW7ZscX/fHD/88IN27dqlPXv2SJL7nqWoqChFRUWpoqJCkydPVmVlpf7yl7+ooqLCfYotMjKy2ccBAACBo8OEI0le3SwlSWvXrtWcOXPcy9OnT5ckLVq0SFlZWfroo4/0/vvvS5IGDRrkMXfHjh3q37//yRUMAAA6nXYNRyd6Cq2oqKjJ9U6ns8lP0L744ovVjg/jAQAAP8TfVgMAALAgHAEAAFgQjgAAACwIRwAAABaEIwAAAAvCEQAAgAXhCAAAwIJwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACw6PDhyOl0yjAMpaWl1VuXnp4uwzDkdDobnOtyufT73/9e55xzjkJDQxUdHa1rr71We/bsaeWqAQCAv+rw4UiSHA6HCgoKdOTIEfdYVVWV8vPzFRsb2+i8yspKffTRR7rrrrv00UcfqbCwUGVlZZoyZUpblA0AAPxQl/YuoDlGjRqlbdu2qbCwUDNnzpQkFRYWKjY2VnFxcY3O69Gjh0pKSjzGnnjiCY0ZM0a7du1qMlg1JGHJBh3tEup9Ay2s/IGU9i4BAIBOyy/CkSSlpqYqNzfXHY5WrVqlOXPmqLS01Kv9HDhwQIZhqGfPno1uU11drerqavdyRUWFJMkeZMpmM72uvaW5XK42O0ZbHKujoOfAQM+BgZ4Dw4l69vW1MEzTbP//2jfB6XRq//79WrlypRwOh8rKyiRJQ4cO1e7duzV37lz17NlTeXl5J9xXVVWVLrzwQg0dOlSrV69udLusrCxlZ2fXG8/Pz1dISIjPvQAAgLZTWVmpGTNm6MCBAwoPD2/2PL85cxQZGamUlBTl5eXJNE2lpKSoT58+7vWrV6/WvHnz3MvFxcVKTEx0L7tcLk2bNk2maWr58uVNHiszM1MLFixwL1dUVMjhcOi+TUE6Gmxrwa5880lWUqsfw+VyqaSkRJMmTVJwcHCrH68joGd67qzomZ47qxP1XHflx1t+E46k45fWMjIyJEk5OTke66ZMmaKEhAT3ckxMjPv7umC0c+dOvfHGGydMj3a7XXa7vd54da2ho8eMk2mhRbTlmz44ODhg/pHVoefAQM+BgZ4DQ2M9+/o6+FU4Sk5OVk1NjQzDUFKS59mTsLAwhYWF1ZtTF4y+/PJLbdy4URERET4f//3MS09qPgAA6Pj8KhzZbDZt2bLF/f2JuFwu/fKXv9RHH32kl19+WceOHdPevXslSb1791bXrl1btV4AAOB//CocSfLqhqqvv/5aa9eulSSNHDnSY93GjRt18cUXt2BlAACgM+jw4ehET6EVFRU1uq5///7q4A/jAQCADsYvPiEbAACgrRCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACw6fDhyOp0yDENpaWn11qWnp8swDDmdzib3sWXLFk2ZMkU9evRQaGiozjvvPO3atauVKgYAAP6sS3sX0BwOh0MFBQVatmyZunfvLkmqqqpSfn6+YmNjm5y7bds2jRs3Ttddd52ys7MVHh6uTz/9VN26dfO6joQlG3S0S2iT25Q/kOL1fgEAQMfhF+Fo1KhR2rZtmwoLCzVz5kxJUmFhoWJjYxUXF9fk3DvvvFM/+9nPtHTpUvfYwIEDW7VeAADgv/wiHElSamqqcnNz3eFo1apVmjNnjkpLSxudU1tbq1deeUW/+93vlJSUpE2bNikuLk6ZmZmaOnVqo/Oqq6tVXV3tXq6oqJAk2YNM2Wxmk3W6XK7mN9WB1fXRWfppDnoODPQcGOg5MJyoZ19fC8M0zab/a9/OnE6n9u/fr5UrV8rhcKisrEySNHToUO3evVtz585Vz549lZeXV2/u3r17ddpppykkJET33XefJkyYoPXr1+uOO+7Qxo0bNX78+AaPmZWVpezs7Hrj+fn5CgkJadH+AABA66isrNSMGTN04MABhYeHN3ue35w5ioyMVEpKivLy8mSaplJSUtSnTx/3+tWrV2vevHnu5eLiYvfls1/84he65ZZbJEkjR47UO++8oxUrVjQajjIzM7VgwQL3ckVFhRwOh+7bFKSjwbYm6/wkK8nnHjsSl8ulkpISTZo0ScHBwe1dTpugZ3rurOiZnjurE/Vcd+XHW34TjqTjl9YyMjIkSTk5OR7rpkyZooSEBPdyTEyMbDabunTpomHDhnlse+aZZ+qf//xno8ex2+2y2+31xqtrDR09ZjRZY2d7QwYHB3e6nk6EngMDPQcGeg4MjfXs6+vgV+EoOTlZNTU1MgxDSUmeZ2jCwsIUFhZWb855553nvhRX54svvlC/fv28Pv77mZcqIiLC63kAAMB/+FU4stls2rJli/v75li4cKF+/etf66KLLnLfc/TSSy81eSM3AAAIXH4VjiR5dUOVJF1xxRVasWKFlixZovnz5+uMM87Q3/72N40bN66VKgQAAP6sw4ejhp5CsyoqKjrhPlJTU5WamtoyBQEAgE6tw//5EAAAgLZEOAIAALAgHAEAAFgQjgAAACwIRwAAABaEIwAAAAvCEQAAgAXhCAAAwIJwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABg0eHDkdPplGEYSktLq7cuPT1dhmHI6XQ2Oj8rK0tDhw5VaGioevXqpYkTJ+r9999vxYoBAIA/69LeBTSHw+FQQUGBli1bpu7du0uSqqqqlJ+fr9jY2CbnDhkyRE888YQGDBigI0eOaNmyZZo8ebK2bt2qyMhIr+pIWLJBR7uENriu/IEUr/YFAAA6pg5/5kiSRo0aJYfDocLCQvdYYWGhYmNjFR8f3+TcGTNmaOLEiRowYIDOOussPfroo6qoqNB//vOf1i4bAAD4Ib84cyRJqampys3N1cyZMyVJq1at0pw5c1RaWtrsfdTU1OjJJ59Ujx49NGLEiEa3q66uVnV1tXu5oqJCkmQPMmWzmQ3Ocblcza7DH9T109n6ago9BwZ6Dgz0HBhO1LOvr4VhmmbD/7XvIJxOp/bv36+VK1fK4XCorKxMkjR06FDt3r1bc+fOVc+ePZWXl9foPl5++WVNnz5dlZWVOu2001RUVKTzzjuv0e2zsrKUnZ1dbzw/P18hISEn3RMAAGh9lZWVmjFjhg4cOKDw8PBmz/ObcFRUVKSrrrpKw4cPl2ma+uSTT/TCCy9o6tSp6tmzpyZNmqR58+a55xUXFysxMVGSdPjwYX3zzTfat2+fVq5cqTfeeEPvv/+++vbt2+AxGzpz5HA4NGxhgY4GN3zP0SdZSS3YdftzuVwqKSnRpEmTFBwc3N7ltAl6pufOip7pubM6Uc8VFRXq06eP1+HIby6rSccvrWVkZEiScnJyPNZNmTJFCQkJ7uWYmBj396GhoRo0aJAGDRqk888/X4MHD9bTTz+tzMzMBo9jt9tlt9vrjVfXGjp6zGhwTmd9IwYHB3fa3hpDz4GBngMDPQeGxnr29XXwq3CUnJysmpoaGYahpCTPMzVhYWEKCwtr1n5qa2s9zgw11/uZlyoiIsLreQAAwH/4VTiy2WzasmWL+/sTOXz4sBYvXqwpU6botNNO0759+5STk6Ovv/5av/rVr1q7XAAA4If8KhxJ8uqaoc1m0+eff65nnnlG+/btU0REhM477zy99dZbOuuss1qxSgAA4K86fDhq6ik0SSoqKmp0Xbdu3Tw+GwkAAOBE/OJDIAEAANoK4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACwIRwAAABaEIwAAAAvCEQAAgEWLhaP9+/e31K4AAADajU/h6MEHH9Rzzz3nXp42bZoiIiIUExOjf//73y1WHAAAQFvzKRytWLFCDodDklRSUqKSkhIVFxfrsssu08KFC1u0QAAAgLbk0x+e3bt3rzscvfzyy5o2bZomT56s/v37KyEhoUULBAAAaEs+nTnq1auXdu/eLUlav369Jk6cKEkyTVPHjh1rueoAAADamE9njq688krNmDFDgwcP1vfff6/LLrtMkrRp0yYNGjSoRQsEAABoSz6Fo2XLlql///7avXu3li5dqlNOOUWS9M033+jGG29s0QIBAADakk/hKDg4WLfddlu98VtuueWkCwIAAGhPPn/O0f/8z/9o3Lhxio6O1s6dOyVJjz32mP7+97+3WHGS5HQ6ZRiG0tLS6q1LT0+XYRhyOp3N2ldaWpoMw9Bjjz3WojUCAIDOw6dwtHz5ci1YsECXXXaZ9u/f774Ju2fPnq0SPBwOhwoKCnTkyBH3WFVVlfLz8xUbG9usfbz44ot67733FB0d3eL1AQCAzsOncPT4449r5cqVuvPOO2Wz2dzj5557rj7++OMWK67OqFGj5HA4VFhY6B4rLCxUbGys4uPjTzj/66+/1k033aTVq1crODjY5zoSlmxQ/9tfUf/bX/F5HwAAoGPzKRzt2LGjwVBit9t1+PDhky6qIampqcrNzXUvr1q1SnPmzDnhvNraWs2aNUsLFy7UWWed1Sq1AQCAzsOnG7Lj4uK0efNm9evXz2N8/fr1OvPMM1uksJ+65pprlJmZ6b6/6e2331ZBQYFKS0ubnPfggw+qS5cumj9/frOPVV1drerqavdyRUWFJMkeZMpmMyVJLpfLyw78S11/nb1PK3oODPQcGOg5MJyoZ19fC5/C0YIFC5Senq6qqiqZpql//etfWrNmjZYsWaKnnnrKp0JOJDIyUikpKcrLy5NpmkpJSVGfPn3c61evXq158+a5l4uLixUSEqI//vGP+uijj2QYRrOPtWTJEmVnZ9cb/0N8rUJCjt9ftW7dupPoxn+UlJS0dwltjp4DAz0HBnoODI31XFlZ6dP+fApHc+fOVffu3fWHP/xBlZWVmjFjhqKjo/XHP/5R06dP96mQ5khNTVVGRoYkKScnx2PdlClTPP50SUxMjP785z/ru+++87hp+9ixY7r11lv12GOPqby8vMHjZGZmasGCBe7liooKORwO3bcpSEeDj99j9UlWUku11SG5XC6VlJRo0qRJJ3Wflj+hZ3rurOiZnjurE/Vcd+XHW16Ho6NHjyo/P19JSUmaOXOmKisrdejQIfXt29enAryRnJysmpoaGYahpCTPcBIWFqawsDCPsVmzZrn/tEmdpKQkzZo1q8n7lex2u+x2e73x6lpDR48dPwMVKG+84ODggOm1Dj0HBnoODPQcGBrr2dfXwetw1KVLF6WlpWnLli2SpJCQEIWEhPh0cG/ZbDb3ca1PyTUmIiJCERERHmPBwcGKiorSGWec4fXx38+8tN7+AABA5+LT02pjxozRpk2bWrqWZgkPD1d4eHi7HBsAAHR+Pt1zdOONN+rWW2/VV199pdGjRys0NNRj/fDhw1ukOEnKy8trcn1RUZFX+2vsPiMAAADJx3BUd9O19fF4wzBkmqYMw3B/YjYAAIC/8Skc7dixo6XrAAAA6BB8Ckc//fBHAACAzsKncPTss882uf7aa6/1qRgAAID25lM4+u1vf+ux7HK5VFlZqa5duyokJIRwBAAA/JZPj/L/+OOPHl+HDh1SWVmZxo0bpzVr1rR0jQAAAG3Gp3DUkMGDB+uBBx6od1YJAADAn7RYOJKOf3r2nj17WnKXAAAAbcqne47Wrl3rsWyapr755hs98cQTuvDCC1ukMAAAgPbgUziaOnWqx7JhGIqMjNQll1yiRx55pCXqAgAAaBc+haPa2tqWrgMAAKBD8Omeo3vuuUeVlZX1xo8cOaJ77rnnpIsCAABoLz6Fo+zsbB06dKjeeGVlpbKzs0+6KAAAgPbiUziq+wOzP/Xvf/9bvXv3PumiAAAA2otX9xz16tVLhmHIMAwNGTLEIyAdO3ZMhw4dUlpaWosXCQAA0Fa8CkePPfaYTNNUamqqsrOz1aNHD/e6rl27qn///ho7dmyLFwkAANBWvApHs2fPliTFxcXpggsuUHBwcKsUBQAA0F58epR//Pjx7u+rqqpUU1PjsT48PPzkqgIAAGgnPt2QXVlZqYyMDPXt21ehoaHq1auXx1dLcjqdMgyjwXuZ0tPTZRiGnE7nCedbv5KTk1u0RgAA0Hn4FI4WLlyoN954Q8uXL5fdbtdTTz2l7OxsRUdH69lnn23pGuVwOFRQUKAjR464x6qqqpSfn6/Y2NgTzk9OTtY333zj/lqzZo1PdSQs2eDTPAAA4D98uqz20ksv6dlnn9XFF1+sOXPmKDExUYMGDVK/fv20evVqzZw5s0WLHDVqlLZt26bCwkL3vgsLCxUbG6u4uLgTzrfb7YqKimrRmgAAQOfkUzj64YcfNGDAAEnH7y/64YcfJEnjxo3Tb37zm5arziI1NVW5ubnucLRq1SrNmTNHpaWlJ5xbWlqqvn37qlevXrrkkkt03333KSIiotHtq6urVV1d7V6uqKiQJNmDTLlcrpNrxE/U9Rko/Ur0HCjoOTDQc2A4Uc++vhaGaZqmt5OGDx+uxx9/XOPHj9fEiRM1cuRIPfzww/p//+//aenSpfrqq698KqYhTqdT+/fv18qVK+VwOFRWViZJGjp0qHbv3q25c+eqZ8+eysvLa3B+QUGBQkJCFBcXp23btumOO+7QKaeconfffVc2m63BOVlZWQ1+0nd+fr5CQkJarDcAANB6KisrNWPGDB04cMCrh8V8CkfLli2TzWbT/Pnz9frrr+vyyy+XaR4/q/Loo4/qt7/9rbe7bFRdOCoqKtJVV12l4cOHyzRNffLJJ3rhhRc0depU9ezZU5MmTdK8efPc84qLi5WYmFhvf9u3b9fAgQP1+uuv69JLL23wmA2dOXI4HBq2sECbF1/ZYr11ZC6XSyUlJZo0aVLAfGQDPdNzZ0XP9NxZnajniooK9enTx+tw5NNltVtuucX9/cSJE/X555/rww8/1KBBgzR8+HBfdtksqampysjIkCTl5OR4rJsyZYoSEhLcyzExMQ3uY8CAAerTp4+2bt3aaDiy2+2y2+31xqtrjYB5w9UJDg6m5wBAz4GBngMDPXuO+8KncGRVVVWlfv36qV+/fie7qxNKTk5WTU2NDMNQUlKSx7qwsDCFhYWdcB9fffWVvv/+e5122mleH//9zIbDFAAA6Dx8epT/2LFjuvfeexUTE6NTTjlF27dvlyTdddddevrpp1u0QCubzaYtW7bos88+a/R+IatDhw5p4cKFeu+991ReXq4NGzboF7/4hQYNGlQvXAEAAEg+hqPFixcrLy9PS5cuVdeuXd3jZ599tp566qkWK64h4eHhzb5uaLPZ9J///EdTpkzRkCFDdN1112n06NF66623GrxsBgAA4NNltWeffVZPPvmkLr30Uo9Prh4xYoQ+//zzFitOUqNPodUpKipqdF337t316quvtmg9AACgc/PpzNHXX3+tQYMG1Ruvra0NqM9XAAAAnY9P4WjYsGF666236o2/8MILio+PP+miAAAA2otPl9XuvvtuzZ49W19//bVqa2tVWFiosrIyPfvss3r55ZdbukYAAIA249WZo+3bt8s0Tf3iF7/QSy+9pNdff12hoaG6++67tWXLFr300kuaNGlSa9UKAADQ6rw6czR48GB988036tu3rxITE9W7d299/PHHOvXUU1urPgAAgDbl1Zmjn/6lkeLiYh0+fLhFCwIAAGhPPt2QXceHP8sGAADQoXkVjgzDkGEY9cYAAAA6C6/uOTJNU06n0/3p0lVVVUpLS1NoaKjHdoWFhS1XIQAAQBvyKhzNnj3bY/maa65p0WIAAADam1fhKDc3t7XqAAAA6BBO6oZsAACAzoZwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFu0ajpxOpwzDUFpaWr116enpMgxDTqez0fmFhYWaPHmyIiIiZBiGNm/eXG+bJ598UhdffLHCw8NlGIb279/fcg0AAIBOp93PHDkcDhUUFOjIkSPusaqqKuXn5ys2NrbJuYcPH9a4ceP04IMPNrpNZWWlkpOTdccdd7RYzQAAoPPy6kMgW8OoUaO0bds2FRYWaubMmZKOnxGKjY1VXFxck3NnzZolSSovL290m5tvvlmSVFpaetK1JizZoK0PTzvp/QAAgI6r3c8cSVJqaqrHp2+vWrVKc+bMaceKAABAoGr3M0fS8b/RlpmZqZ07d0qS3n77bRUUFLTI2R5fVFdXq7q62r1cUVEhSbIHmXK5XO1SU1ur6zNQ+pXoOVDQc2Cg58Bwop59fS06RDiKjIxUSkqK8vLyZJqmUlJS1KdPH/f61atXa968ee7l4uJiJSYmtlo9S5YsUXZ2dr3xP8TXat26da123I6opKSkvUtoc/QcGOg5MNBzYGis58rKSp/21yHCkXT80lpGRoYkKScnx2PdlClTlJCQ4F6OiYlp1VoyMzO1YMEC93JFRYUcDofu2xSkzYt/1qrH7ihcLpdKSko0adIkBQcHt3c5bYKe6bmzomd67qxO1HPdlR9vdZhwlJycrJqaGhmGoaSkJI91YWFhCgsLa7Na7Ha77HZ7vfE3fz8xYN5wdYKDg+k5ANBzYKDnwEDPnuO+6DDhyGazacuWLe7vm+OHH37Qrl27tGfPHklSWVmZJCkqKkpRUVGSpL1792rv3r3aunWrJOnjjz9WWFiYYmNj1bt375ZuAwAA+LkO8bRanfDwcIWHhzd7+7Vr1yo+Pl4pKSmSpOnTpys+Pl4rVqxwb7NixQrFx8fr+uuvlyRddNFFio+P19q1a1u2eAAA0Cm065mjvLy8JtcXFRU1ud7pdDb5CdqSlJWVpaysLK/qAgAAgatDnTkCAABob4QjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACwIRwAAABaEIwAAAIt2DUdOp1OGYSgtLa3euvT0dBmGIafT2ej8wsJCTZ48WRERETIMQ5s3b663TVVVldLT0xUREaFTTjlFV111lb799tsW7AIAAHQm7X7myOFwqKCgQEeOHHGPVVVVKT8/X7GxsU3OPXz4sMaNG6cHH3yw0W1uueUWvfTSS3r++ef1j3/8Q3v27NGVV17ZYvUDAIDOpUt7FzBq1Cht27ZNhYWFmjlzpqTjZ4RiY2MVFxfX5NxZs2ZJksrLyxtcf+DAAT399NPKz8/XJZdcIknKzc3VmWeeqffee0/nn39+yzUCAAA6hXYPR5KUmpqq3NxcdzhatWqV5syZo9LS0pPa74cffiiXy6WJEye6x4YOHarY2Fi9++67jYaj6upqVVdXu5crKiokSS6XSy6X66Rq8hd1fQZKvxI9Bwp6Dgz0HBhO1LOvr0WHCEfXXHONMjMztXPnTknS22+/rYKCgpMOR3v37lXXrl3Vs2dPj/FTTz1Ve/fubXTekiVLlJ2dXW9848aNCgkJOama/E1JSUl7l9Dm6Dkw0HNgoOfA0FjPlZWVPu2vQ4SjyMhIpaSkKC8vT6ZpKiUlRX369HGvX716tebNm+deLi4uVmJiYqvVk5mZqQULFriXKyoq5HA4NGHCBEVERLTacTsSl8ulkpISTZo0ScHBwe1dTpugZ3rurOiZnjurE/Vcd+XHWx0iHEnHL61lZGRIknJycjzWTZkyRQkJCe7lmJiYZu0zKipKNTU12r9/v8fZo2+//VZRUVGNzrPb7bLb7fXGg4ODA+YNV4eeAwM9BwZ6Dgz07Dnuiw4TjpKTk1VTUyPDMJSUlOSxLiwsTGFhYV7vc/To0QoODtaGDRt01VVXSZLKysq0a9cujR07tkXqBgAAnUuHCUc2m01btmxxf98cP/zwg3bt2qU9e/ZIOh58pONnjKKiotSjRw9dd911WrBggXr37q3w8HDddNNNGjt2LE+qAQCABrX75xxZhYeHKzw8vNnbr127VvHx8UpJSZEkTZ8+XfHx8VqxYoV7m2XLlunnP/+5rrrqKl100UWKiopSYWFhi9cOAAA6h3Y9c5SXl9fk+qKioibXO53OJj9BW5K6deumnJycevcxAQAANKRDnTkCAABob4QjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACwIRwAAABYdPhw5nU4ZhqG0tLR669LT02UYhpxOZ6Pzv/32WzmdTkVHRyskJETJycn68ssvW7FiAADgzzp8OJIkh8OhgoICHTlyxD1WVVWl/Px8xcbGNjrPNE1NnTpV27dv19///ndt2rRJ/fr108SJE3X48OG2KB0AAPgZvwhHo0aNksPhUGFhoXussLBQsbGxio+Pb3Tel19+qffee0/Lly/XeeedpzPOOEPLly/XkSNHtGbNmrYoHQAA+Jku7V1Ac6Wmpio3N1czZ86UJK1atUpz5sxRaWlpo3Oqq6slSd26dXOPBQUFyW6365///Kfmzp3b6Ly6uZJUUVEhSXK5XHK5XCfbil+o6zNQ+pXoOVDQc2Cg58Bwop59fS0M0zRNn6tqA06nU/v379fKlSvlcDhUVlYmSRo6dKh2796tuXPnqmfPnsrLy6s31+VyadCgQUpISNCf//xnhYaGatmyZbr99ts1efJkvfrqqw0eMysrS9nZ2fXG8/PzFRIS0qL9AQCA1lFZWakZM2bowIEDCg8Pb/Y8vzlzFBkZqZSUFOXl5ck0TaWkpKhPnz7u9atXr9a8efPcy8XFxUpMTFRhYaGuu+469e7dWzabTRMnTtRll12mpjJhZmamFixY4F6uqKiQw+HQhAkTFBER0ToNdjAul0slJSWaNGmSgoOD27ucNkHP9NxZ0TM9d1Yn6rnuyo+3/CYcSccvrWVkZEiScnJyPNZNmTJFCQkJ7uWYmBhJ0ujRo7V582YdOHBANTU1ioyMVEJCgs4999xGj2O322W32+uNBwcHB8wbrg49BwZ6Dgz0HBjo2XPcF34VjpKTk1VTUyPDMJSUlOSxLiwsTGFhYY3O7dGjh6TjN2l/8MEHuvfee1u1VgAA4J/8KhzZbDZt2bLF/X1zPP/884qMjFRsbKw+/vhj/fa3v9XUqVM1efLk1iwVAAD4Kb8KR5K8uqFKkr755hstWLBA3377rU477TRde+21uuuuu1qpOgAA4O86fDhq6Ck0q6KioibXz58/X/Pnz2+5ggAAQKfmFx8CCQAA0FYIRwAAABaEIwAAAAvCEQAAgAXhCAAAwIJwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWHT4cOZ1OGYahtLS0euvS09NlGIacTmej8w8dOqSMjAydfvrp6t69u4YNG6YVK1a0YsUAAMCfdfhwJEkOh0MFBQU6cuSIe6yqqkr5+fmKjY1tcu6CBQu0fv16/eUvf9GWLVt08803KyMjQ2vXrm3tsgEAgB/yi3A0atQoORwOFRYWuscKCwsVGxur+Pj4Jue+8847mj17ti6++GL1799fN9xwg0aMGKF//etfrV02AADwQ13au4DmSk1NVW5urmbOnClJWrVqlebMmaPS0tIm511wwQVau3atUlNTFR0drdLSUn3xxRdatmxZo3Oqq6tVXV3tXq6oqJAkuVwuuVyuk2/GD9T1GSj9SvQcKOg5MNBzYDhRz76+FoZpmqbPVbUBp9Op/fv3a+XKlXI4HCorK5MkDR06VLt379bcuXPVs2dP5eXlNTi/urpaN9xwg5599ll16dJFQUFBWrlypa699tpGj5mVlaXs7Ox64/n5+QoJCWmRvgAAQOuqrKzUjBkzdODAAYWHhzd7nt+cOYqMjFRKSory8vJkmqZSUlLUp08f9/rVq1dr3rx57uXi4mIlJibq8ccf13vvvae1a9eqX79+evPNN5Wenq7o6GhNnDixwWNlZmZqwYIF7uWKigo5HA5NmDBBERERrddkB+JyuVRSUqJJkyYpODi4vctpE/RMz50VPdNzZ3Winuuu/HjLb8KRdPzSWkZGhiQpJyfHY92UKVOUkJDgXo6JidGRI0d0xx136MUXX1RKSookafjw4dq8ebMefvjhRsOR3W6X3W6vNx4cHBwwb7g69BwY6Dkw0HNgoGfPcV/4VThKTk5WTU2NDMNQUlKSx7qwsDCFhYV5jFVUVMjlcikoyPO+c5vNptra2lavFwAA+B+/Ckc2m01btmxxf38i4eHhGj9+vBYuXKju3burX79++sc//qFnn31Wjz76aGuXCwAA/JBfhSNJXt1QJUkFBQXKzMzUzJkz9cMPP6hfv35avHhxgx8qCQAA0OHDUWNPodUpKipqcn1UVJRyc3NbriAAANCp+cWHQAIAALQVwhEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACwIRwAAABaEIwAAAAvCEQAAgAXhCAAAwIJwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAiw4fjpxOpwzDUFpaWr116enpMgxDTqez0fmGYTT49dBDD7Vi1QAAwF91+HAkSQ6HQwUFBTpy5Ih7rKqqSvn5+YqNjW1y7jfffOPxtWrVKhmGoauuuqq1ywYAAH7IL8LRqFGj5HA4VFhY6B4rLCxUbGys4uPjm5wbFRXl8fX3v/9dEyZM0IABA1q7bAAA4Ie6tHcBzZWamqrc3FzNnDlTkrRq1SrNmTNHpaWlzd7Ht99+q1deeUXPPPNMk9tVV1erurravVxRUSFJcrlccrlc3hfvh+r6DJR+JXoOFPQcGOg5MJyoZ19fC8M0TdPnqtqA0+nU/v37tXLlSjkcDpWVlUmShg4dqt27d2vu3Lnq2bOn8vLyTrivpUuX6oEHHtCePXvUrVu3RrfLyspSdnZ2vfH8/HyFhIT43AsAAGg7lZWVmjFjhg4cOKDw8PBmz/ObM0eRkZFKSUlRXl6eTNNUSkqK+vTp416/evVqzZs3z71cXFysxMREj32sWrVKM2fObDIYSVJmZqYWLFjgXq6oqJDD4dCECRMUERHRQh11bC6XSyUlJZo0aZKCg4Pbu5w2Qc/03FnRMz13Vifque7Kj7f8JhxJxy+tZWRkSJJycnI81k2ZMkUJCQnu5ZiYGI/1b731lsrKyvTcc8+d8Dh2u112u73eeHBwcMC84erQc2Cg58BAz4GBnj3HfeFX4Sg5OVk1NTUyDENJSUke68LCwhQWFtbo3KefflqjR4/WiBEjWrtMAADgx/wqHNlsNm3ZssX9fXNVVFTo+eef1yOPPNJapQEAgE7Cr8KRJK9uqKpTUFAg0zR19dVXt0JFAACgM+nw4ehET6EVFRWdcB833HCDbrjhhpYpCAAAdGp+8SGQAAAAbYVwBAAAYEE4AgAAsCAcAQAAWBCOAAAALAhHAAAAFoQjAAAAC8IRAACABeEIAADAgnAEAABgQTgCAACwIBwBAABYEI4AAAAsCEcAAAAWhCMAAAALwhEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACy6tHcB/sA0TUnSwYMHFRwc3M7VtA2Xy6XKykpVVFTQcydGz/TcWdEzPUtSRUWFpP/773hzEY6a4fvvv5ckxcXFtXMlAADAWwcPHlSPHj2avT3hqBl69+4tSdq1a5dXL64/q6iokMPh0O7duxUeHt7e5bQJeqbnzoqe6bmzOlHPpmnq4MGDio6O9mq/hKNmCAo6fmtWjx49AuYNVyc8PJyeAwA9BwZ6Dgz07MmXkxrckA0AAGBBOAIAALAgHDWD3W7XokWLZLfb27uUNkPPgYGeAwM9BwZ6bjmG6e3zbQAAAJ0YZ44AAAAsCEcAAAAWhCMAAAALwhEAAIAF4ej/l5OTo/79+6tbt25KSEjQv/71rya3f/755zV06FB169ZN55xzjtatW9dGlbYcb3peuXKlEhMT1atXL/Xq1UsTJ0484WvUEXn7c65TUFAgwzA0derU1i2wFXjb8/79+5Wenq7TTjtNdrtdQ4YM8bv3t7c9P/bYYzrjjDPUvXt3ORwO3XLLLaqqqmqjak/em2++qcsvv1zR0dEyDENFRUUnnFNaWqpRo0bJbrdr0KBBysvLa/U6W5K3PRcWFmrSpEmKjIxUeHi4xo4dq1dffbVtim0hvvyc67z99tvq0qWLRo4c2Wr1tQZfeq6urtadd96pfv36yW63q3///lq1apVXxyUcSXruuee0YMECLVq0SB999JFGjBihpKQkfffddw1u/8477+jqq6/Wddddp02bNmnq1KmaOnWqPvnkkzau3Hfe9lxaWqqrr75aGzdu1LvvviuHw6HJkyfr66+/buPKfedtz3XKy8t12223KTExsY0qbTne9lxTU6NJkyapvLxcL7zwgsrKyrRy5UrFxMS0ceW+87bn/Px83X777Vq0aJG2bNmip59+Ws8995zuuOOONq7cd4cPH9aIESOUk5PTrO137NihlJQUTZgwQZs3b9bNN9+suXPn+lVY8LbnN998U5MmTdK6dev04YcfasKECbr88su1adOmVq605Xjbc539+/fr2muv1aWXXtpKlbUeX3qeNm2aNmzYoKefflplZWVas2aNzjjjDO8ObMIcM2aMmZ6e7l4+duyYGR0dbS5ZsqTB7adNm2ampKR4jCUkJJjz5s1r1Tpbkrc9/9TRo0fNsLAw85lnnmmtElucLz0fPXrUvOCCC8ynnnrKnD17tvmLX/yiDSptOd72vHz5cnPAgAFmTU1NW5XY4rztOT093bzkkks8xhYsWGBeeOGFrVpna5Fkvvjii01u87vf/c4866yzPMZ+/etfm0lJSa1YWetpTs8NGTZsmJmdnd3yBbUBb3r+9a9/bf7hD38wFy1aZI4YMaJV62pNzem5uLjY7NGjh/n999+f1LEC/sxRTU2NPvzwQ02cONE9FhQUpIkTJ+rdd99tcM67777rsb0kJSUlNbp9R+NLzz9VWVkpl8vl/qO8HZ2vPd9zzz3q27evrrvuurYos0X50vPatWs1duxYpaen69RTT9XZZ5+t+++/X8eOHWursk+KLz1fcMEF+vDDD92X3rZv365169bpZz/7WZvU3B78/XdYS6itrdXBgwf95neYr3Jzc7V9+3YtWrSovUtpE2vXrtW5556rpUuXKiYmRkOGDNFtt92mI0eOeLWfgP/Ds/v27dOxY8d06qmneoyfeuqp+vzzzxucs3fv3ga337t3b6vV2ZJ86fmnfv/73ys6OrreL9iOypee//nPf+rpp5/W5s2b26DCludLz9u3b9cbb7yhmTNnat26ddq6datuvPFGuVwuv/jl6kvPM2bM0L59+zRu3DiZpqmjR48qLS3Nry6reaux32EVFRU6cuSIunfv3k6VtZ2HH35Yhw4d0rRp09q7lFbz5Zdf6vbbb9dbb72lLl0C4z/327dv1z//+U9169ZNL774ovbt26cbb7xR33//vXJzc5u9n4A/cwTvPfDAAyooKNCLL76obt26tXc5reLgwYOaNWuWVq5cqT59+rR3OW2mtrZWffv21ZNPPqnRo0fr17/+te68806tWLGivUtrNaWlpbr//vv1pz/9SR999JEKCwv1yiuv6N57723v0tBK8vPzlZ2drb/+9a/q27dve5fTKo4dO6YZM2YoOztbQ4YMae9y2kxtba0Mw9Dq1as1ZswY/exnP9Ojjz6qZ555xquzR4ERJZvQp08f2Ww2ffvttx7j3377raKiohqcExUV5dX2HY0vPdd5+OGH9cADD+j111/X8OHDW7PMFuVtz9u2bVN5ebkuv/xy91htba0kqUuXLiorK9PAgQNbt+iT5MvP+bTTTlNwcLBsNpt77Mwzz9TevXtVU1Ojrl27tmrNJ8uXnu+66y7NmjVLc+fOlSSdc845Onz4sG644QbdeeedCgrqfP8fsrHfYeHh4Z3+rFFBQYHmzp2r559/3m/OfPvi4MGD+uCDD7Rp0yZlZGRIOv47zDRNdenSRa+99pouueSSdq6y5Z122mmKiYlRjx493GNnnnmmTNPUV199pcGDBzdrP53vX72XunbtqtGjR2vDhg3usdraWm3YsEFjx45tcM7YsWM9tpekkpKSRrfvaHzpWZKWLl2qe++9V+vXr9e5557bFqW2GG97Hjp0qD7++GNt3rzZ/TVlyhT30z0Oh6Mty/eJLz/nCy+8UFu3bnUHQUn64osvdNppp3X4YCT51nNlZWW9AFQXDs1O+qcn/f13mK/WrFmjOXPmaM2aNUpJSWnvclpVeHh4vd9haWlpOuOMM7R582YlJCS0d4mt4sILL9SePXt06NAh99gXX3yhoKAgnX766c3f0Undzt1JFBQUmHa73czLyzM/++wz84YbbjB79uxp7t271zRN05w1a5Z5++23u7d/++23zS5dupgPP/ywuWXLFnPRokVmcHCw+fHHH7dXC17ztucHHnjA7Nq1q/nCCy+Y33zzjfvr4MGD7dWC17zt+af88Wk1b3vetWuXGRYWZmZkZJhlZWXmyy+/bPbt29e877772qsFr3nb86JFi8ywsDBzzZo15vbt283XXnvNHDhwoDlt2rT2asFrBw8eNDdt2mRu2rTJlGQ++uij5qZNm8ydO3eapmmat99+uzlr1iz39tu3bzdDQkLMhQsXmlu2bDFzcnJMm81mrl+/vr1a8Jq3Pa9evdrs0qWLmZOT4/E7bP/+/e3Vgte87fmn/PFpNW97PnjwoHn66aebv/zlL81PP/3U/Mc//mEOHjzYnDt3rlfHJRz9/x5//HEzNjbW7Nq1qzlmzBjzvffec68bP368OXv2bI/t//rXv5pDhgwxu3btap511lnmK6+80sYVnzxveu7Xr58pqd7XokWL2r7wk+Dtz9nKH8ORaXrf8zvvvGMmJCSYdrvdHDBggLl48WLz6NGjbVz1yfGmZ5fLZWZlZZkDBw40u3XrZjocDvPGG280f/zxx7Yv3EcbN25s8N9nXZ+zZ882x48fX2/OyJEjza5du5oDBgwwc3Nz27zuk+Ftz+PHj29ye3/gy8/Zyh/DkS89b9myxZw4caLZvXt38/TTTzcXLFhgVlZWenVcwzQ76XljAAAAHwT8PUcAAABWhCMAAAALwhEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAQLt48803dfnllys6OlqGYaioqMjrffz1r3/VyJEjFRISon79+umhhx466boIRwA6PKfTKcMw6n1t3bq1vUsDcBIOHz6sESNGKCcnx6f5xcXFmjlzptLS0vTJJ5/oT3/6k5YtW6YnnnjipOriE7IBdHhOp1PffvutcnNzPcYjIyPdfyS2PblcLgUHB7d3GYBfMwxDL774oqZOneoeq66u1p133qk1a9Zo//79Ovvss/Xggw/q4osvliTNmDFDLpdLzz//vHvO448/rqVLl2rXrl0yDMOnWjhzBMAv2O12RUVFeXw1Fox27typyy+/XL169VJoaKjOOussrVu3zr3+008/1c9//nOFh4crLCxMiYmJ2rZtmySptrZW99xzj04//XTZ7XaNHDlS69evd88tLy+XYRh67rnnNH78eHXr1k2rV6+WJD311FM688wz1a1bNw0dOlR/+tOfWvEVATq/jIwMvfvuuyooKNB//vMf/epXv1JycrK+/PJLScfDU7du3TzmdO/eXV999ZV27tzp83G7nFTVANABpaenq6amRm+++aZCQ0P12Wef6ZRTTpEkff3117rooot08cUX64033lB4eLjefvttHT16VJL0xz/+UY888oj+/Oc/Kz4+XqtWrdKUKVP06aefavDgwe5j3H777XrkkUcUHx/vDkh33323nnjiCcXHx2vTpk26/vrrFRoaqtmzZ7fL6wD4s127dik3N1e7du1SdHS0JOm2227T+vXrlZubq/vvv19JSUm65ZZb5HQ6NWHCBG3dulWPPPKIJOmbb75R//79fTt4C/zRXABoVbNnzzZtNpsZGhrq/vrlL3/Z6PbnnHOOmZWV1eC6zMxMMy4uzqypqWlwfXR0tLl48WKPsfPOO8+88cYbTdM0zR07dpiSzMcee8xjm4EDB5r5+fkeY/fee685duzYE/YHwDQlmS+++KJ7+eWXXzYlefy7Dw0NNbt06WJOmzbNNE3TrK2tNX/3u9+Z3bp1M202m9mrVy8zKyvLlGS+9957PtfCmSMAfmHChAlavny5ezk0NLTRbefPn6/f/OY3eu211zRx4kRdddVVGj58uCRp8+bNSkxMbPAeoYqKCu3Zs0cXXnihx/iFF16of//73x5j5557rvv7w4cPa9u2bbruuut0/fXXu8ePHj2qHj16eNcoAEnSoUOHZLPZ9OGHH9a7hF53JtgwDD344IO6//77tXfvXkVGRmrDhg2SpAEDBvh8bMIRAL8QGhqqQYMGNWvbuXPnKikpSa+88opee+01LVmyRI888ohuuukmde/evcXqqXPo0CFJ0sqVK5WQkOCxXUe4YRzwR/Hx8Tp27Ji+++47JSYmNrmtzWZTTEyMJGnNmjUaO3asIiMjfT42N2QD6JQcDofS0tJUWFioW2+9VStXrpQkDR8+XG+99ZZcLle9OeHh4YqOjtbbb7/tMf72229r2LBhjR7r1FNPVXR0tLZv365BgwZ5fMXFxbVsY0AncujQIW3evFmbN2+WJO3YsUObN2/Wrl27NGTIEM2cOVPXXnutCgsLtWPHDv3rX//SkiVL9Morr0iS9u3bpxUrVujzzz/X5s2b9dvf/lbPP/+8HnvssZOqizNHADqdm2++WZdddpmGDBmiH3/8URs3btSZZ54p6fjTL48//rimT5+uzMxM9ejRQ++9957GjBmjM844QwsXLtSiRYs0cOBAjRw5Urm5udq8ebP7ibTGZGdna/78+erRo4eSk5NVXV2tDz74QD/++KMWLFjQFm0DfueDDz7QhAkT3Mt1/1Zmz56tvLw85ebm6r777tOtt96qr7/+Wn369NH555+vn//85+45zzzzjG677TaZpqmxY8eqtLRUY8aMOam6CEcAOp1jx44pPT1dX331lcLDw5WcnKxly5ZJkiIiIvTGG29o4cKFGj9+vGw2m0aOHOm+z2j+/Pk6cOCAbr31Vn333XcaNmyY1q5d6/GkWkPmzp2rkJAQPfTQQ1q4cKFCQ0N1zjnn6Oabb27tdgG/dfHFF8ts4uMWg4ODlZ2drezs7AbX9+nTR++++26L18WHQAIAAFhwzxEAAIAF4QgAAMCCcAQAAGBBOAIAALAgHAEAAFgQjgAAACwIRwAAABaEIwAAAAvCEQAAgAXhCAAAwIJwBAAAYEE4AgAAsPj/ADMVeP5ak/J0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "# Initializing XGBoost regression model with specified parameters\n",
    "XGB = XGBRegressor(n_jobs=-1, max_depth=10, n_estimators=100, learning_rate=0.2)\n",
    "\n",
    "# Fitting the XGBoost model with training data\n",
    "XGB.fit(X_train, Y_train)\n",
    "\n",
    "# Assigning feature names to the booster object for visualization\n",
    "XGB.get_booster().feature_names = [f'M{x-12}' for x in range(12)]\n",
    "\n",
    "# Plotting feature importance using XGBoost's plot_importance function\n",
    "xgb.plot_importance(XGB, importance_type='total_gain', show_values=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb86ee9",
   "metadata": {},
   "source": [
    "### Evaluation and Early Stopping\n",
    "When an XGBoost model is trained on a dataset, you can measure—after each iteration—its accuracy against an evaluation set.\n",
    "\n",
    "**Evaluation Set**\n",
    "An evaluation set is a set of data that is left aside from the training set to be used as a monitoring dataset during the training. A validation set (random subset of the training set) or a holdout set (last period of the training set) can be used as an evaluation set.\n",
    "\n",
    "If you want to optimize your model’s parameters, the best practice is of course to run a cross-validation random search. But rather than trying different models with a different number of trees, you could grow your model indefinitely, and stop it when there is no more improvement on the evaluation set (for some consecutive iterations).\n",
    "\n",
    "In practice, once the model does not see an accuracy improvement on the evaluation test for a determined number of extra trees, XGBoost will revert to the last iteration that brought extra accuracy to the evaluation set. With this technique, you get rid of the burden of number-of-trees optimization, and you are sure to grow your model up to the right level. \n",
    "               This early stopping technique will help us avoid overfitting our model to the training set, and at the same time, reduce training time. One stone, two birds. The early stopping technique is a very useful capability of XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 996\n",
      "Best score: 32.34355200170273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.15)\n",
    "\n",
    "# Setting up the XGBoost regressor with specified hyperparameters\n",
    "# Including the `eval_metric` and `early_stopping_rounds` during initialization\n",
    "XGB = XGBRegressor(\n",
    "    n_jobs=-1, \n",
    "    max_depth=10, \n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.01, \n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric='mae'\n",
    ")\n",
    "\n",
    "# Fitting the model on the training data\n",
    "# Note: No need to specify `early_stopping_rounds` and `eval_metric` here\n",
    "XGB.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    verbose=False, \n",
    "    eval_set=[(x_val, y_val)]\n",
    ")\n",
    "\n",
    "# Printing the best iteration number\n",
    "print(f'Best iteration: {XGB.best_iteration}')\n",
    "\n",
    "# Printing the best score\n",
    "print(f'Best score: {XGB.best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f5f0e",
   "metadata": {},
   "source": [
    "#### Using holdout dataset as the evaluation dataset\n",
    "Instead of a validation set, you can also use a holdout dataset as the evaluation dataset. This can perform better on some datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_holdout(df, x_len=12, y_len=1, test_loops=12, holdout_loops=0):\n",
    "    D = df.values\n",
    "    rows, periods = D.shape\n",
    "    \n",
    "    # Training set creation\n",
    "    train_loops = periods + 1 - x_len - y_len - test_loops\n",
    "    train = []\n",
    "    for col in range(train_loops):\n",
    "        train.append(D[:, col:col + x_len + y_len])\n",
    "    train = np.vstack(train)\n",
    "    X_train, Y_train = np.split(train, [-y_len], axis=1)\n",
    "    \n",
    "    # Holdout set creation\n",
    "    if holdout_loops > 0:\n",
    "        X_train, X_holdout = np.split(X_train, [-rows * holdout_loops], axis=0)\n",
    "        Y_train, Y_holdout = np.split(Y_train, [-rows * holdout_loops], axis=0)\n",
    "    else:\n",
    "        X_holdout, Y_holdout = np.array([]), np.array([])\n",
    "    \n",
    "    # Test set creation\n",
    "    if test_loops > 0:\n",
    "        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)\n",
    "        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)\n",
    "    else:\n",
    "        # No test set: X_test is used to generate the future forecast\n",
    "        X_test = D[:, -x_len:]\n",
    "        Y_test = np.full((X_test.shape[0], y_len), np.nan)  # Dummy value\n",
    "    \n",
    "    # Formatting required for scikit-learn\n",
    "    if y_len == 1:\n",
    "        Y_train = Y_train.ravel()\n",
    "        Y_test = Y_test.ravel()\n",
    "        Y_holdout = Y_holdout.ravel()\n",
    "    \n",
    "    return X_train, Y_train, X_holdout, Y_holdout, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training, holdout, and test sets using a custom function\n",
    "X_train, Y_train, X_holdout, Y_holdout, X_test, Y_test = datasets_holdout(df, x_len=12, y_len=1, test_loops=12, holdout_loops=12)\n",
    "\n",
    "# Initializing and training XGBoost regression model\n",
    "XGB = XGBRegressor(n_jobs=-1, max_depth=10, n_estimators=2000, learning_rate=0.01)\n",
    "XGB = XGB.fit(X_train, Y_train, verbose=False, eval_metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset  Mean Absolute Error (MAE)\n",
      "0  Holdout                  39.447520\n",
      "1     Test                  31.553178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Predicting values for holdout and test sets\n",
    "predictions_holdout = XGB.predict(X_holdout)\n",
    "predictions_test = XGB.predict(X_test)\n",
    "\n",
    "# Calculating MAE for holdout and test sets\n",
    "mae_holdout = mean_absolute_error(Y_holdout, predictions_holdout)\n",
    "mae_test = mean_absolute_error(Y_test, predictions_test)\n",
    "\n",
    "# Creating a DataFrame with the results\n",
    "results_data = {\n",
    "    'Dataset': ['Holdout', 'Test'],\n",
    "    'Mean Absolute Error (MAE)': [mae_holdout, mae_test]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Displaying the table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** It's important to compare the MAE to some baseline or to the range of the target variable to understand the magnitude of these errors fully. Additionally, if these datasets are different in size, distribution, or feature space, the MAE values may not be directly comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4730b5f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Grid for Gradient Boosting Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7d5e6",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "Now that we have defined the parameter space we want to test, we can continue and perform a cross-validation random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "Tuned XGBoost Parameters:  {'subsample': 0.6, 'reg_lambda': 1.1, 'reg_alpha': 5, 'n_estimators': 1000, 'min_child_weight': 20, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Initialize the XGBRegressor with default parameters\n",
    "XGB = XGBRegressor()\n",
    "\n",
    "# Define the hyperparameters to be tuned\n",
    "params = {\n",
    "    'max_depth': [5, 6, 7, 8, 10, 11],\n",
    "    'learning_rate': [0.005, 0.01, 0.025, 0.05, 0.1, 0.15],\n",
    "    'colsample_bynode': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # max_features\n",
    "    'colsample_bylevel': [0.8, 0.9, 1.0],  # max_features per level\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],  # max_features\n",
    "    'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],  # max_samples\n",
    "    'min_child_weight': [5, 10, 15, 20, 25],  # min_samples_leaf\n",
    "    'reg_alpha': [1, 5, 10, 20, 50],\n",
    "    'reg_lambda': [0.01, 0.05, 0.1, 0.5, 1.1],    'n_estimators': [1000]\n",
    "}\n",
    "\n",
    "# Define RandomizedSearchCV\n",
    "XGB_cv = RandomizedSearchCV(\n",
    "    XGB, \n",
    "    params, \n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    n_iter=1000, \n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "XGB_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Tuned XGBoost Parameters: ', XGB_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In this setup, the eval_set parameter is not directly set in the fit_params since it's not straightforward to use with cross-validation (like RandomizedSearchCV), as each fold will have a different validation set.\n",
    "\n",
    "**Pro-Tip - Double Search**\n",
    "\n",
    "If you don't feel confident about setting the various parameter ranges to be tested, do not hesitate to run two optimizations one after the other- the first one with wide parameter ranges; then, a second one performed in more detail around the first optimal values found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train XGBoostRegressor with RandomizedSearchCV-Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV object with best parameters determined\n",
    "best_params = XGB_cv.best_params_\n",
    "\n",
    "# Initialize XGBRegressor with the best parameters\n",
    "XGB = XGBRegressor(n_jobs=-1, **best_params)\n",
    "\n",
    "# Assuming fit_params is defined as before, without early stopping rounds and eval_metric\n",
    "fit_params = {\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "# Fit the model with the training data\n",
    "XGB.fit(x_train, y_train, **fit_params)\n",
    "\n",
    "# Print the best iteration and score if available\n",
    "# These attributes are only available if early stopping is used\n",
    "if hasattr(XGB.get_booster(), 'best_iteration'):\n",
    "    print(f'Best iteration: {XGB.get_booster().best_iteration}')\n",
    "if hasattr(XGB.get_booster(), 'best_score'):\n",
    "    print(f'Best score: {XGB.get_booster().best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training and test sets\n",
    "y_train_pred = XGB.predict(X_train)\n",
    "y_test_pred = XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    MAE  RMSE  Bias\n",
      "XGBoost_optimized                  \n",
      "Train              13.9  33.9  -0.2\n",
      "Test               17.7  44.6   2.9\n"
     ]
    }
   ],
   "source": [
    "# Define the kpi_ML function\n",
    "def kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=\"\"):\n",
    "    df = pd.DataFrame(columns=['MAE', 'RMSE', 'Bias'], index=['Train', 'Test'])\n",
    "    df.index.name = name\n",
    "\n",
    "    df.loc['Train', 'MAE'] = 100 * np.mean(np.abs(Y_train - Y_train_pred)) / np.mean(Y_train)\n",
    "    df.loc['Train', 'RMSE'] = 100 * np.sqrt(np.mean((Y_train - Y_train_pred)**2)) / np.mean(Y_train)\n",
    "    df.loc['Train', 'Bias'] = 100 * np.mean((Y_train - Y_train_pred)) / np.mean(Y_train)\n",
    "\n",
    "    df.loc['Test', 'MAE'] = 100 * np.mean(np.abs(Y_test - Y_test_pred)) / np.mean(Y_test)\n",
    "    df.loc['Test', 'RMSE'] = 100 * np.sqrt(np.mean((Y_test - Y_test_pred)**2)) / np.mean(Y_test)\n",
    "    df.loc['Test', 'Bias'] = 100 * np.mean((Y_test - Y_test_pred)) / np.mean(Y_test)\n",
    "\n",
    "    df = df.astype(float).round(1)  # Round numbers for display\n",
    "    print(df)\n",
    "\n",
    "# Evaluate the model predictions\n",
    "kpi_ML(Y_train, y_train_pred, Y_test, y_test_pred, name='XGBoost_optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9380d1",
   "metadata": {},
   "source": [
    "### Multiple Periods Evaluation\n",
    "Just like AdaBoost, XGBoost unfortunately cannot forecast multiple periods at once, so we will also use scikit-learn’s MultiOutputRegressor. To make the model faster, you should set n_jobs=1 in XGBRegressor and n_jobs=-1 for MultiOutputRegressor. (In other words, a thread will be working independently on each of the future forecast periods, rather than multiple threads working on single forecast periods one by one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8642790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.2, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=100, n_jobs=1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...),\n",
       "                     n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.2, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=100, n_jobs=1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...),\n",
       "                     n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=1,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=1,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.2, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=100, n_jobs=1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...),\n",
       "                     n_jobs=-1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Training and testing\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=6, test_loops=12)\n",
    "XGB = XGBRegressor(n_jobs=1, max_depth=10, n_estimators=100, learning_rate=0.2)\n",
    "multi = MultiOutputRegressor(XGB, n_jobs=-1)\n",
    "multi.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0            1            2            3           4  \\\n",
      "Make                                                                           \n",
      "Alfa Romeo      10.184089     8.149643     7.404906     9.503287   11.133018   \n",
      "Aston Martin     0.190329     0.682681     0.191748     0.093967    0.176659   \n",
      "Audi           733.652588   742.841309   594.797241   659.938660  743.312378   \n",
      "BMW           1060.885254  1101.544800  1228.265137  1222.016724  929.175598   \n",
      "Bentley          0.166028     0.284376     0.311742     0.516105    0.599086   \n",
      "\n",
      "                       5  \n",
      "Make                      \n",
      "Alfa Romeo     16.790682  \n",
      "Aston Martin    0.640640  \n",
      "Audi          620.856140  \n",
      "BMW           743.211670  \n",
      "Bentley         0.230187  \n"
     ]
    }
   ],
   "source": [
    "# Future Forecast\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=6, test_loops=0)\n",
    "XGB = XGBRegressor(n_jobs=1, max_depth=10, n_estimators=100, learning_rate=0.2)\n",
    "multi = MultiOutputRegressor(XGB, n_jobs=-1)\n",
    "multi.fit(X_train, Y_train)\n",
    "\n",
    "# Creating the forecast DataFrame with predictions and setting the index\n",
    "forecast = pd.DataFrame(data=multi.predict(X_test), index=df.index)\n",
    "\n",
    "print(forecast.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
