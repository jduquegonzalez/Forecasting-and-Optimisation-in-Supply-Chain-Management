{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Regression Model for Car Sales Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries and modules\n",
    "We are going to import necessary libraries and modules, including MLPRegressor for neural network regression, RandomizedSearchCV for hyperparameter tuning, pandas for data manipulation, numpy for numerical operations, and StandardScaler for feature standardization. These components are typically used to build and optimize a neural network regression model for data analysis and prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Processing\n",
    "Let's define a function to import and process the data from a CSV file. It'll read the data, format it into a period-wise structure by combining year and month, and create a pivot table indexed by car make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period        2007-01  2007-02  2007-03  2007-04  2007-05  2007-06  2007-07  \\\n",
      "Make                                                                          \n",
      "Alfa Romeo         16        9       21       20       17       21       14   \n",
      "Aston Martin        0        0        1        0        4        3        3   \n",
      "Audi              599      498      682      556      630      498      562   \n",
      "BMW               352      335      365      360      431      477      403   \n",
      "Bentley             0        0        0        0        0        1        0   \n",
      "\n",
      "Period        2007-08  2007-09  2007-10  ...  2016-04  2016-05  2016-06  \\\n",
      "Make                                     ...                              \n",
      "Alfa Romeo         12       15       10  ...        3        1        2   \n",
      "Aston Martin        0        0        0  ...        0        0        1   \n",
      "Audi              590      393      554  ...      685      540      551   \n",
      "BMW               348      271      562  ...     1052      832      808   \n",
      "Bentley             0        0        0  ...        0        0        1   \n",
      "\n",
      "Period        2016-07  2016-08  2016-09  2016-10  2016-11  2016-12  2017-01  \n",
      "Make                                                                         \n",
      "Alfa Romeo          1        6       15        3        4        3        6  \n",
      "Aston Martin        0        0        0        0        0        0        0  \n",
      "Audi              687      794      688      603      645      827      565  \n",
      "BMW               636     1031     1193     1096     1663      866     1540  \n",
      "Bentley             1        1        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the import_data function\n",
    "def import_data():\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)\n",
    "    df = pd.pivot_table(data=data, values='Quantity', index='Make', columns='Period', aggfunc='sum', fill_value=0)\n",
    "    return df\n",
    "\n",
    "# URL of the CSV file\n",
    "file_path = \"https://supchains.com/wp-content/uploads/2021/07/norway_new_car_sales_by_make1.csv\"\n",
    "\n",
    "# Create the DataFrame using the import_data function\n",
    "df = import_data()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Now, we are going to define the datasets function, which will prepare the data for machine learning model training and testing. It'll take the DataFrame and specified lengths for input (x_len) and output (y_len) sequences, creating training and testing datasets. The function will arrange the data into overlapping sequences of a defined length for model training and split the data into features (X) and labels (Y). Additionally, it'll support creating test sets based on a specified number of loops, and format the data for compatibility with Scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets function with x_len as an argument\n",
    "def datasets(df, x_len=12, y_len=1, test_loops=12):\n",
    "    D = df.values\n",
    "    rows, periods = D.shape\n",
    "    \n",
    "    # Training set creation\n",
    "    loops = periods + 1 - x_len - y_len\n",
    "    train = []\n",
    "    for col in range(loops):\n",
    "        train.append(D[:, col:col + x_len + y_len])\n",
    "    train = np.vstack(train)\n",
    "    X_train, Y_train = np.split(train, [-y_len], axis=1)\n",
    "    \n",
    "    # Test set creation\n",
    "    if test_loops > 0:\n",
    "        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)\n",
    "        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)\n",
    "    else:\n",
    "        X_test = D[:, -x_len:]\n",
    "        Y_test = np.full((X_test.shape[0], y_len), np.nan)\n",
    "    \n",
    "    # Formatting required for scikit-learn\n",
    "    if y_len == 1:\n",
    "        Y_train = Y_train.ravel()\n",
    "        Y_test = Y_test.ravel()\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Scaling\n",
    "Here we are going to prepare and scale the data for the model. We'll start by splitting the dataset into training and testing sets using the datasets function. Following this, we'll employ the StandardScaler from Scikit-learn to scale the data. X_train and X_test will be transformed such that they'll have a mean of 0 and a standard deviation of 1, a standard practice to normalize data before feeding it into many machine learning algorithms. This step is crucial for models that are sensitive to the scale of the input data, such as neural networks and distance-based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, Y_train, X_test, Y_test = datasets(df)\n",
    "\n",
    "#Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Calculation\n",
    "Let's define now the kpi_ML function, which calculates key performance metrics for evaluating the  model. It computes the Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Bias for both training and testing datasets. These metrics are essential for understanding the model's accuracy and prediction error. The results are displayed in a pandas DataFrame, providing a clear and concise summary of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kpi_ML function\n",
    "def kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=\"\"):\n",
    "    df = pd.DataFrame(columns=['MAE', 'RMSE', 'Bias'], index=['Train', 'Test'])\n",
    "    df.index.name = name\n",
    "\n",
    "    df.loc['Train', 'MAE'] = 100 * np.mean(np.abs(Y_train - Y_train_pred)) / np.mean(Y_train)\n",
    "    df.loc['Train', 'RMSE'] = 100 * np.sqrt(np.mean((Y_train - Y_train_pred)**2)) / np.mean(Y_train)\n",
    "    df.loc['Train', 'Bias'] = 100 * np.mean((Y_train - Y_train_pred)) / np.mean(Y_train)\n",
    "\n",
    "    df.loc['Test', 'MAE'] = 100 * np.mean(np.abs(Y_test - Y_test_pred)) / np.mean(Y_test)\n",
    "    df.loc['Test', 'RMSE'] = 100 * np.sqrt(np.mean((Y_test - Y_test_pred)**2)) / np.mean(Y_test)\n",
    "    df.loc['Test', 'Bias'] = 100 * np.mean((Y_test - Y_test_pred)) / np.mean(Y_test)\n",
    "\n",
    "    df = df.astype(float).round(1)  # Round numbers for display\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring and Training a Neural Network Regressor\n",
    "We are going to set up and train the neural network using Scikit-learn's MLPRegressor. Weâ€™ll begin by defining a set of fixed parameters (param_fixed), including the activation function ('relu'), optimizer ('adam'), and settings for early stopping, validation fraction, tolerance, and maximum iterations. Then, an MLPRegressor model will be instantiated with these parameters and a predefined hidden layer size. The model is then trained using scaled training data (X_train_scaled, Y_train) and subsequently makes predictions on both training and testing data. Finally, the function kpi_ML is called to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MAE  RMSE  Bias\n",
      "NN                     \n",
      "Train  17.5  44.0  -0.5\n",
      "Test   17.6  43.6   1.0\n"
     ]
    }
   ],
   "source": [
    "param_fixed = {\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'early_stopping': True,\n",
    "    'n_iter_no_change': 30,\n",
    "    'validation_fraction': 0.1,\n",
    "    'tol': 0.0001,\n",
    "    'max_iter': 2000  \n",
    "}\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes=(20, 20), **param_fixed, verbose=False)\n",
    "NN.fit(X_train_scaled, Y_train)\n",
    "Y_train_pred = NN.predict(X_train_scaled) \n",
    "Y_test_pred = NN.predict(X_test_scaled) \n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='NN')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Hyperparameter Grid for MLPRegressor Tuning\n",
    "Here we define an enhanced range of hyperparameters for tuning the MLP. It includes varied hidden_layer_sizes, logarithmically scaled alpha and learning_rate_init values, and refined ranges for beta_1 and beta_2. This setup aims to improve the efficiency and effectiveness of the MLP tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE  RMSE  Bias\n",
      "NN optimized                  \n",
      "Train         17.4  43.8  -0.2\n",
      "Test          17.6  43.6   1.3\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [(x, y) for x in range(10, 60, 10) for y in range(10, 60, 10)]\n",
    "alpha = np.logspace(-3, 1, 5)\n",
    "learning_rate_init = np.logspace(-5, -1, 5)\n",
    "beta_1 = np.linspace(0.85, 0.99, 5)\n",
    "beta_2 = np.linspace(0.99, 0.9999, 5)\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': hidden_layer_sizes, \n",
    "    'alpha': alpha, \n",
    "    'learning_rate_init': learning_rate_init, \n",
    "    'beta_1': beta_1, \n",
    "    'beta_2': beta_2\n",
    "}\n",
    "NN = MLPRegressor(**param_fixed)\n",
    "NN_cv = RandomizedSearchCV(NN, param_dist, cv=10, verbose=0, n_jobs=-1, n_iter=200, scoring='neg_mean_absolute_error')\n",
    "NN_cv.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Extract the best parameters from the randomized search\n",
    "best_params = NN_cv.best_params_\n",
    "\n",
    "# Create a new MLPRegressor model with the best parameters\n",
    "optimized_NN = MLPRegressor(**best_params)\n",
    "\n",
    "# Fit the model with your scaled training data\n",
    "optimized_NN.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Predict using the optimized model\n",
    "Y_train_pred = optimized_NN.predict(X_train_scaled)\n",
    "Y_test_pred = optimized_NN.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the optimized model\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='NN optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating forecasts using the optimized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0\n",
      "Make                     \n",
      "Alfa Romeo       6.221273\n",
      "Aston Martin     1.034259\n",
      "Audi           649.657690\n",
      "BMW           1256.049390\n",
      "Bentley          1.165328\n",
      "...                   ...\n",
      "Think            1.098836\n",
      "Toyota        1450.411142\n",
      "Volkswagen    1994.160108\n",
      "Volvo          923.392109\n",
      "Westfield        1.098836\n",
      "\n",
      "[65 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Splitting and scaling the data\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=1, test_loops=0)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Setting up and fitting the randomized search\n",
    "NN = MLPRegressor(**param_fixed)\n",
    "NN_cv = RandomizedSearchCV(NN, param_dist, cv=10, verbose=0, n_jobs=-1, n_iter=200, scoring='neg_mean_absolute_error')\n",
    "NN_cv.fit(X_train_scaled, Y_train)  \n",
    "\n",
    "best_params = NN_cv.best_params_\n",
    "optimized_NN = MLPRegressor(**best_params)\n",
    "optimized_NN.fit(X_train_scaled, Y_train)  # Fit the optimized model\n",
    "\n",
    "# Generating forecasts using the optimized model\n",
    "forecast = pd.DataFrame(data=optimized_NN.predict(X_test_scaled), index=df.index)\n",
    "print(forecast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
