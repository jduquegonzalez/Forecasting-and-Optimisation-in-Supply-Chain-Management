{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccbd9480",
   "metadata": {},
   "source": [
    "## Categorical Features\n",
    "**(With comments and codes from the Nicolas Vandepu's book \"Data Science for Supply Chain Forecasting\")**\n",
    "\n",
    "Most supply chains serve different markets (often through different channels) and have different product families. What if a machine learning model could benefit from these extra pieces of information: Am I selling this to market A? Is this product part of family B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07a5e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Quantity                                                          \\\n",
      "Period        2007-01 2007-02 2007-03 2007-04 2007-05 2007-06 2007-07 2007-08   \n",
      "Make                                                                            \n",
      "Alfa Romeo         16       9      21      20      17      21      14      12   \n",
      "Aston Martin        0       0       1       0       4       3       3       0   \n",
      "Audi              599     498     682     556     630     498     562     590   \n",
      "BMW               352     335     365     360     431     477     403     348   \n",
      "Bentley             0       0       0       0       0       1       0       0   \n",
      "\n",
      "                              ...                                          \\\n",
      "Period       2007-09 2007-10  ... 2016-04 2016-05 2016-06 2016-07 2016-08   \n",
      "Make                          ...                                           \n",
      "Alfa Romeo        15      10  ...       3       1       2       1       6   \n",
      "Aston Martin       0       0  ...       0       0       1       0       0   \n",
      "Audi             393     554  ...     685     540     551     687     794   \n",
      "BMW              271     562  ...    1052     832     808     636    1031   \n",
      "Bentley            0       0  ...       0       0       1       1       1   \n",
      "\n",
      "                                                      \n",
      "Period       2016-09 2016-10 2016-11 2016-12 2017-01  \n",
      "Make                                                  \n",
      "Alfa Romeo        15       3       4       3       6  \n",
      "Aston Martin       0       0       0       0       0  \n",
      "Audi             688     603     645     827     565  \n",
      "BMW             1193    1096    1663     866    1540  \n",
      "Bentley            0       0       0       0       0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the import_data function\n",
    "def import_data():\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)\n",
    "    df = pd.pivot_table(data=data, values=['Quantity'], index='Make', columns='Period', aggfunc='sum', fill_value=0)\n",
    "    return df\n",
    "\n",
    "# URL of the CSV file\n",
    "file_path = \"https://supchains.com/wp-content/uploads/2021/07/norway_new_car_sales_by_make1.csv\"\n",
    "\n",
    "# Create the DataFrame using the import_data function\n",
    "df = import_data()\n",
    "\n",
    "# Now 'df' contains the data from the provided URL in the desired format.\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "We will update our datasets() function so that it can properly use a categorical input. \n",
    "\n",
    "The idea is that we will flag the categorical columns in the historical dataset df based on their names. We can easily identify categorical columns by using the prefix_sep.\n",
    "\n",
    "Prepares datasets for machine learning models with categorical variables included.\n",
    "    \n",
    "**Parameters:**\n",
    "- df (DataFrame): The input data frame containing the time series and categorical data.\n",
    "- x_len (int): The length of the input sequence.\n",
    "- y_len (int): The length of the output sequence.\n",
    "- test_loops (int): The number of loops to be used for testing.\n",
    "- cat_name (str): The string identifier for categorical columns.\n",
    "   \n",
    "**Returns:**\n",
    "- X_train (numpy.ndarray): The training data set for input features.\n",
    "- Y_train (numpy.ndarray): The training data set for output features.\n",
    "- X_test (numpy.ndarray): The test data set for input features.\n",
    "- Y_test (numpy.ndarray): The test data set for output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def datasets_cat(df, x_len=12, y_len=1, test_loops=12, cat_name='_'):\n",
    "    # Select columns that contain categorical data\n",
    "    col_cat = [col for col in df.columns if cat_name in col]\n",
    "    \n",
    "    # Separate historical demand data and categorical data\n",
    "    D = df.drop(columns=col_cat).values  # Historical demand\n",
    "    C = df[col_cat].values  # Categorical info\n",
    "    \n",
    "    # Determine the shape of the historical data\n",
    "    rows, periods = D.shape\n",
    "\n",
    "    # Training set creation\n",
    "    loops = periods + 1 - x_len - y_len\n",
    "    train = []\n",
    "    \n",
    "    # Loop to create training sequences\n",
    "    for col in range(loops):\n",
    "        train.append(D[:, col:col+x_len+y_len])\n",
    "    \n",
    "    # Stack sequences vertically\n",
    "    train = np.vstack(train)\n",
    "    \n",
    "    # Split sequences into input (X) and output (Y) features\n",
    "    X_train, Y_train = np.split(train, [-y_len], axis=1)\n",
    "    \n",
    "    # Concatenate categorical data with input features\n",
    "    X_train = np.hstack((np.vstack([C]*loops), X_train))\n",
    "\n",
    "    # Test set creation\n",
    "    if test_loops > 0:\n",
    "        # Split the data into training and test sets if test_loops are specified\n",
    "        X_train, X_test = np.split(X_train, [-rows*test_loops], axis=0)\n",
    "        Y_train, Y_test = np.split(Y_train, [-rows*test_loops], axis=0)\n",
    "    else:\n",
    "        # No test set: X_test is used to generate the future forecast\n",
    "        X_test = np.hstack((C, D[:, -x_len:]))\n",
    "        Y_test = np.full((X_test.shape[0], y_len), np.nan)  # Dummy value for Y_test\n",
    "\n",
    "    # Formatting required for scikit-learn\n",
    "    if y_len == 1:\n",
    "        Y_train = Y_train.ravel()\n",
    "        Y_test = Y_test.ravel()\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s now use one-hot label encoding to differentiate each brand. We can retrieve the brand easily from the index, and then one-hot encode it using the pandas function pd.get_dummies().\n",
    "\n",
    "Using one-hot label encoding (otherwise known as dummification) rather than integer encoding will allow you to remove useless features and only keep the meaningful ones, thus reducing overfitting. It is then preferred not to initially remove one random dummy column from the one-hot labels, but rather to wait for analysis only to remove the meaningless ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data using the function defined above\n",
    "df = import_data()\n",
    "# One-hot encode the 'Brand' column and return a DataFrame with new columns for each brand\n",
    "df['Brand'] = df.index  # Set 'Brand' column as the index of the DataFrame\n",
    "df = pd.get_dummies(df, columns=['Brand'], prefix_sep='_')  # Apply one-hot encoding\n",
    "\n",
    "# Prepare the training and test datasets using the datasets_cat function\n",
    "X_train, Y_train, X_test, Y_test = datasets_cat(df, x_len=12, y_len=1, test_loops=12, cat_name='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have proper training and test sets, we can pursue our data science process with a proper feature optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
