{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccbd9480",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "(With comments and codes from the Nicolas Vandepu's book \"Data Science for Supply Chain Forecasting\")\n",
    "\n",
    "We will transform automobile sales data into a pivot table format. We will start by importing data from a specified CSV file URL, then combine the 'Year' and 'Month' columns to create a 'Period' column, converting it into a period format for cleaner and more meaningful indexing. The core function, import_data, takes the file path as an argument and returns a DataFrame where the 'Make' of cars is indexed, and sales data is aggregated monthly. This organized pivot table format is particularly useful for further analysis and visualization in sales trend studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation: Pivot Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Quantity                                                          \\\n",
      "Period        2007-01 2007-02 2007-03 2007-04 2007-05 2007-06 2007-07 2007-08   \n",
      "Make                                                                            \n",
      "Alfa Romeo         16       9      21      20      17      21      14      12   \n",
      "Aston Martin        0       0       1       0       4       3       3       0   \n",
      "Audi              599     498     682     556     630     498     562     590   \n",
      "BMW               352     335     365     360     431     477     403     348   \n",
      "Bentley             0       0       0       0       0       1       0       0   \n",
      "\n",
      "                              ...                                          \\\n",
      "Period       2007-09 2007-10  ... 2016-04 2016-05 2016-06 2016-07 2016-08   \n",
      "Make                          ...                                           \n",
      "Alfa Romeo        15      10  ...       3       1       2       1       6   \n",
      "Aston Martin       0       0  ...       0       0       1       0       0   \n",
      "Audi             393     554  ...     685     540     551     687     794   \n",
      "BMW              271     562  ...    1052     832     808     636    1031   \n",
      "Bentley            0       0  ...       0       0       1       1       1   \n",
      "\n",
      "                                                      \n",
      "Period       2016-09 2016-10 2016-11 2016-12 2017-01  \n",
      "Make                                                  \n",
      "Alfa Romeo        15       3       4       3       6  \n",
      "Aston Martin       0       0       0       0       0  \n",
      "Audi             688     603     645     827     565  \n",
      "BMW             1193    1096    1663     866    1540  \n",
      "Bentley            0       0       0       0       0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def import_data():\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)\n",
    "        df = pd.pivot_table(data=data, values=['Quantity'], index='Make', columns='Period', aggfunc='sum', fill_value=0)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "file_path = \"https://supchains.com/wp-content/uploads/2021/07/norway_new_car_sales_by_make1.csv\"\n",
    "df = import_data()\n",
    "\n",
    "if df is not None:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94032bd",
   "metadata": {},
   "source": [
    "#### Training and Test Sets Creation\n",
    "\n",
    "Now that we have our dataset with the proper formatting, we can create a function datasets() to populate a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d2ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def datasets(df, X_len=12, y_len=1, test_loops=12):\n",
    "    D = df.values\n",
    "    rows, periods = D.shape\n",
    "    \n",
    "    # Training set creation\n",
    "    loops = periods + 1 - X_len - y_len\n",
    "    train = []\n",
    "    for col in range(loops):\n",
    "        train.append(D[:, col:col + X_len + y_len])\n",
    "    train = np.vstack(train)\n",
    "    X_train, Y_train = np.split(train, [-y_len], axis=1)\n",
    "    \n",
    "    # Test set creation\n",
    "    if test_loops > 0:\n",
    "        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)\n",
    "        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)\n",
    "    else:\n",
    "        X_test = D[:, -X_len:]\n",
    "        Y_test = np.full((X_test.shape[0], y_len), np.nan)\n",
    "    \n",
    "    # Formatting required for scikit-learn\n",
    "    if y_len == 1:\n",
    "        Y_train = Y_train.ravel()\n",
    "        Y_test = Y_test.ravel()\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3344d9",
   "metadata": {},
   "source": [
    "#### We can now easily call our new function datasets(df) as well as import_data().\n",
    "\n",
    "We obtain the datasets we need to feed our machine learning algorithm (X_train and Y_train) and the datasets we need to test it (X_test and Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4dcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = import_data()\n",
    "\n",
    "# Create training and test sets using the datasets function\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, X_len=12, y_len=1, test_loops=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5d455",
   "metadata": {},
   "source": [
    "Note: We can change y_len if we want to forecast multiple periods at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be35e4",
   "metadata": {},
   "source": [
    "#### Let’s create a linear regression forecast benchmark. \n",
    "We want to have an indication of what a simple model could do in order to compare its accuracy against our more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Ensure the number of samples matches in X_train and Y_train\n",
    "if X_train.shape[0] != Y_train.shape[0]:\n",
    "    print(\"Number of samples in X_train and Y_train do not match!\")\n",
    "else:\n",
    "    # Create and train the Linear Regression model\n",
    "    reg = LinearRegression() \n",
    "    reg.fit(X_train, Y_train)\n",
    "    \n",
    "    # Generate predictions for the training and test sets\n",
    "    Y_train_pred = reg.predict(X_train)\n",
    "    Y_test_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c032387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearRegression class from sklearn's linear_model module.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression() # Create an instance of the LinearRegression class.\n",
    "reg.fit(X_train, Y_train) # Fit the linear regression model to the training data.\n",
    "\n",
    "# Generate predictions for the training set using the fitted model.\n",
    "Y_train_pred = reg.predict(X_train) # Y_train_pred will contain the model's prediction for the dependent variable based on X_train.\n",
    "\n",
    "# Generate predictions for the test set using the fitted model.\n",
    "Y_test_pred = reg.predict(X_test)   # Y_test_pred will contain the model's prediction for the dependent variable based on X_test.\n",
    "                                    # It's essential for evaluating the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089baf4",
   "metadata": {},
   "source": [
    "#### We can now create a KPI function kpi_ML()\n",
    "It will display the accuracy of our model.\n",
    "\n",
    "Here, we use a DataFrame in order to print the various KPI in a structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=\"\"):\n",
    "\n",
    "    # Create a DataFrame to store Key Performance Indicators (KPIs) for Machine Learning models.\n",
    "    df = pd.DataFrame(columns=['MAE', 'RMSE', 'Bias'], index=['Train', 'Test'])\n",
    "    \n",
    "    # Set the name of the index to the provided 'name' parameter, typically the model name.\n",
    "    df.index.name = name\n",
    "\n",
    "    # Calculate and assign the MAE, RMSE, and Bias for the training dataset.\n",
    "    df.loc['Train', 'MAE'] = 100 * np.mean(np.abs(Y_train - Y_train_pred)) / np.mean(Y_train)\n",
    "    df.loc['Train', 'RMSE'] = 100 * np.sqrt(np.mean((Y_train - Y_train_pred)**2)) / np.mean(Y_train)\n",
    "    df.loc['Train', 'Bias'] = 100 * np.mean((Y_train - Y_train_pred)) / np.mean(Y_train)\n",
    "\n",
    "    # Calculate and assign the MAE, RMSE, and Bias for the test dataset.\n",
    "    df.loc['Test', 'MAE'] = 100 * np.mean(np.abs(Y_test - Y_test_pred)) / np.mean(Y_test)\n",
    "    df.loc['Test', 'RMSE'] = 100 * np.sqrt(np.mean((Y_test - Y_test_pred)**2)) / np.mean(Y_test)\n",
    "    df.loc['Test', 'Bias'] = 100 * np.mean((Y_test - Y_test_pred)) / np.mean(Y_test)\n",
    "\n",
    "    # Round the values in the DataFrame to one decimal place for easier reading and interpretation.\n",
    "    df = df.astype(float).round(1)\n",
    "    \n",
    "    # Print the DataFrame to display the calculated KPIs.\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MAE  RMSE  Bias\n",
      "Regression                  \n",
      "Train       17.8  43.9  -0.0\n",
      "Test        17.8  43.7   1.6\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the function\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f414074",
   "metadata": {},
   "source": [
    "**Attention Point:**\n",
    "Do not worry if the MAE and RMSE of your dataset is much above the example benchmark presented here. In some projects, Nicolas Vandeput has seen MAE as high as 80 to 100%, and RMSE well above 500%. Again, we use a linear regression benchmark precisely to get an order of magnitude of the complexity of a dataset.\n",
    "\n",
    "On a different dataset, with a longer forecast horizon (and more seasonality), linear regressions might not be up to the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e790bd1",
   "metadata": {},
   "source": [
    "#### Make predictions for the future\n",
    "Future Forecast\n",
    "We can now change our hat from data scientist—working with training and test sets to evaluate models—to demand planner—using a model to populate a baseline forecast.\n",
    "\n",
    "We will create a future forecast—the forecast to be used by the supply chain— by using our datasets() function and set test_loops to 0. The function will then return X_test filled-in with the latest demand observations— thus we will be able to use it to predict future demand. Moreover, as we do not keep data aside for the test set, the training dataset (X_train and Y_train) will include the whole historical demand. This will be helpful, as we will use as much training data as possible to feed the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Future_Predicted\n",
      "Make                          \n",
      "Alfa Romeo            6.413065\n",
      "Aston Martin          1.279442\n",
      "Audi                650.220440\n",
      "BMW                1262.958337\n",
      "Bentley               1.465567\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for the future\n",
    "X_future = df.values[:, -X_train.shape[1]:]\n",
    "future_predictions = reg.predict(X_future)\n",
    "future_predictions = future_predictions.reshape(-1, 1)\n",
    "\n",
    "# Create a DataFrame for the future forecast\n",
    "forecast = pd.DataFrame(data=future_predictions, index=df.index, columns=[\"Future_Predicted\"])\n",
    "\n",
    "# Print or use the 'future_forecast' DataFrame as needed\n",
    "print(forecast.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
